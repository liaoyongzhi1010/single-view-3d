1. LFM-3D: Learnable Feature Matching Across Wide Baselines Using 3D Signals
2. NICER-SLAM: Neural Implicit Scene Encoding for RGB SLAM
3. SlimmeRF: Slimmable Radiance Fields
4. RaNeuS: Ray-adaptive Neural Surface Reconstruction
5. POCO: 3D Pose and Shape Estimation with Confidence
6. Objects with Lighting: A Real-World Dataset for Evaluating Reconstruction and Rendering for Object Relighting
7. OPDMulti: Openable Part Detection for Multiple Objects
8. DehazeNeRF: Multi-image Haze Removal and 3D Shape Reconstruction using Neural Radiance Fields
9. Efficient 3D Articulated Human Generation with Layered Surface Volumes
10. 3D Pose Estimation of Two Interacting Hands from a Monocular Event Camera
11. S4C: Self-Supervised Semantic Scene Completion with Neural Fields
12. NCRF: Neural Contact Radiance Fields for Free-viewpoint Rendering of Hand-Object Interactions
13. Zero-BEV: Zero-shot Projection of any First-Person Modality to BEV Maps
14. Out of the Room: Generalizing Event-based Dynamic Motion Segmentation for Complex Scenes
15. Physics-based Indirect Illumination for Inverse Rendering
16. CombiNeRF: a Combination of Regularization Techniques for Few-Shot Neural Radiance Field View Synthesis
17. NeVRF: Neural Video-based Radiance Fields for Long-duration Sequences
18. Mirror-Aware Neural Humans
19. Stable Surface Regularization for Fast Few-Shot NeRF
20. Depth Reconstruction with Neural Signed Distance Fields in Structured Light Systems
21. GHuNeRF:Generalizable Human NeRF from a Monocular Video
22. Consistent-1-to-3: Consistent Image to 3D View Synthesis via Geometry-aware Diffusion Models
23. Generalizing Single-View 3D Shape Retrieval to Occlusions and Unseen Objects
24. Single-view 3D Scene Reconstruction with High-fidelity Shape and Texture
25. Farm3D: Learning Articulated 3D Animals by Distilling 2D Diffusion
26. GAN-Avatar: Controllable Personalized GAN-based Human Head Avatar
27. NeRFMeshing: Distilling Neural Radiance Fields into Geometrically-Accurate 3D Meshes
28. MonoLSS: Learnable Sample Selection For Monocular 3D Detection
29. Control3Diff: Learning Controllable 3D Diffusion Models from Single-view Images
30. Learning to Estimate 6DoF Pose from Limited Data: A Few-Shot, Generalizable, Model-Free Approach using RGB Images
31. A Benchmark Grocery Dataset of Realworld Point Clouds from Single View
32. PlaNeRF: SVD Unsupervised 3D Plane Regularization for NeRF Large-Scale Urban Scene Reconstruction
33. Dynamic Prototype Adaptation with Distillation for Few-shot Point Cloud Segmentation
34. TeCH: Text-guided Reconstruction of Lifelike Clothed Humans
35. Hyper-SNBRDF: Hypernetwork for Neural BRDF using Sinusoidal Activation
36. Dynamic 3D Gaussians: Tracking by Persistent Dynamic View Synthesis
37. Towards Learning Monocular 3D Object Localization From 2D Labels using the Physical Laws of Motion
38. MixRT: Mixed Neural Representations For Real-Time NeRF Rendering
39. Color-NeuS: Reconstructing Neural Implicit Surfaces with Color
40. Deep Event Visual Odometry
41. PanoSSC: Exploring Monocular Panoptic 3D Scene  Reconstruction for Autonomous Driving
42. Addressing Low-Shot MVS by Detecting and Completing Planar Surfaces
43. YOLO-6D-Pose:Enhancing YOLO for Single-Stage Monocular Multi-Object 6D Pose Estimation
44. DynamicSurf: Dynamic Neural RGB-D Surface Reconstruction with an Optimizable Feature Grid
